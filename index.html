<!DOCTYPE html>
<html>
<head>
	<link rel="stylesheet" type="text/css" href="./stylesheets/main.css">
	<title>Milda Norkute</title>
	<link rel="icon" 
      href="favicon_N.ico">
</head>
<body>
    <div class="stars">
<div class="twinkling">
    <div class="clouds">
    <div class="text-container">
	<h1>Hi, I'm Milda Norkute</h1>
	<h2>
        At the moment I'm in between websites. However, I've summarized some of the highlights below --
	</h2>
	<p>I'm <span style="font-weight: 1000">currently</span> a Lead Human Factors Design Engineer (Designer & Researcher) at Thomson Reuters Labs. I specialize in designing for data and AI/ML products. My <span style="font-weight: bold">CHI2021 paper</span> <a target="_blank" href="./../assets/NorkuteXAI.pdf">Towards Explainable AI: Assessing the Usefulness and Impact of Added Explainability Features in Legal Document Summarization</a> is a pretty good representation of what kind of work I do at the labs, as well as this paper on  <a target="_blank" href="./../assets/Extractor.pdf"> Human-in-the-Loop Information Extraction System </a>.
		Designing and coding interactive data visualizations for <a target="_blank" href="https://pbi.trust.org/">Trustlaw's Pro Bono Index</a> is another example project, though a bit less common. A lot of my design work on TR products is confidential. I also have led many design thinking workshops with customers & internally to identify AI innovation opportunities and published paper on what works and what doesn't when running such workshops: <a target="_blank" href="./../assets/CognitiveStrategies4HCAI.pdf">Cognitive Strategy Prompts: Creativity Triggers for Human Centered AI Opportunity Detection</a>.
	</p>
    <p>Before Thomson Reuters I worked as Designer and Front End Developer at CERN <span style="font-weight: bold">(2018-2019)</span> and Nokia <span style="font-weight: bold">(2017 summer)</span>.</p>
	<p><span style="font-weight: bold">2016-2018</span>, I completed a double masters in Human Computer Interaction and Design at Aalto University and KTH Royal Institute of Technology.</p>
	<p>Before starting my career in technology, <span style="font-weight: bold">2014-2016</span> I worked in media research at Newsworks, in London. I graduated with bachelors degree in Psychology from University Bath with first class honours in <span style="font-weight: bold">2014</span>. I also spent a year working in academic research at New Zealand Institute of Language Brain and Behaviour between <span style="font-weight: bold">2012-2013</span>.</p>
	<p><!--You can <a target="_blank" href="./../assets/Norkute_Milda_2023.pdf">download my CV</a> in case I missed something.--> You can contact me through <a target="_blank" href="mailto:milda.norkute@bath.edu">email</a>, or find me online on <a target="_blank" href="https://twitter.com/milda_nor">twitter</a>.</p>
	<h3>
        Publications
	</h3>

<ul>
		<li><span style="font-weight: bold">Milda Norkute</span>, Nadja Herger, Leszek Michalak, Andrew Mulder, and Sally Gao. 2021. Towards Explainable AI: Assessing the Usefulness and Impact of Added Explainability Features in Legal Document Summarization. In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems (CHI EA '21). Association for Computing Machinery, New York, NY, USA, Article 53, 1–7.  <a target="_blank" href="./../assets/NorkuteXAI.pdf">Preprint</a> </li>
		<li><span style="font-weight: bold">Milda Norkute</span>. 2021. AI Explainability: Why One Explanation Cannot Fit All. In The 2021 ACM CHI Workshop on Operationalizing Human-Centered Perspectives in Explainable AI (CHI 2021 HCXAI Workshop) <a target="_blank" href="./../assets/Xai_position_final.pdf">Preprint</a></li>
		<li><span style="font-weight: bold">Milda Norkute</span>. 2021. The Role of Explanations of AI Systems: Beyond Trust and Helping to Form Mental Models. In: Wienrich, C., Wintersberger, P. & Weyers, B. (Hrsg.), Mensch und Computer 2021 - Workshopband. Bonn: Gesellschaft für Informatik e.V. <a target="_blank" href="./../assets/Contribution_387__a.pdf">Preprint</a> </li>
		<li>Johannes Schleith, <span style="font-weight: bold">Milda Norkute</span>, Mary Mikhail, and Daniella Tsar. 2022. Cognitive Strategy Prompts: Creativity Triggers for Human Centered AI Opportunity Detection. In Creativity and Cognition (C&C ’22), June 20–23, 2022, Venice, Italy. ACM, New York, NY, USA, 9 pages. <a target="_blank" href="./../assets/CognitiveStrategies4HCAI.pdf">Preprint</a></li>
		<li>Johannes Schleith, Hella Hoffmann, <span style="font-weight: bold">Milda Norkute</span>, and Brian Cechmanek. 2022. Human-in-the-Loop Information Extraction Increases Efficiency and Trust.  In: Marky, K., Grünefeld, U. & Kosch, T. (Hrsg.), Mensch und Computer 2022 - Workshopband. Bonn: Gesellschaft für Informatik e.V. <a target="_blank" href="./../assets/Extractor.pdf">Preprint</a> </li>
		<li>Aileen Nielsen, Laura Skylaki, <span style="font-weight: bold">Milda Norkute</span>, and Alexander Stremitzer. 2023. Effects of XAI on Legal Process.  In Nineteenth International Conference on Artificial Intelligence and Law (ICAIL 2023), June 19–23, 2023, Braga, Portugal. ACM, NewYork, NY, USA, 5 pages. <a target="_blank" href="./../assets/ICAIL_2023.pdf">Preprint</a> </li>

</ul>	
		<h3>Speaking engagements</h3>  
	<p>I had the pleasure to present at various academic and industry conferences, events and meetups. The list below does not cover internal presentations.
	</p>
	<p><span style="font-weight: 1000">2023</span> </p>
	<ul>
		<li>
			1st Workshop on Legal Information Retrieval at ECIR 2023; <span style="font-weight: 1000">Milda Norkute</span>; Keynote talk: <span style="font-style: italic"> Evaluating legal search from the perspective of the users</span>; April 2 2023.   
		</li>
	</ul>
	<p><span style="font-weight: 1000">2022</span> </p>
	<ul>
		<li>
			1st Workshop on Measuring the Quality of Explanations in Recommender Systems (QUARE) at SIGIR 2022; <span style="font-weight: 1000">Milda Norkute</span>; <span style="font-style: italic">Explainability considerations for summarization, HCI perpective</span>; July 15 2022. <a target="_blank" href="https://sites.google.com/view/quare-2022/">link</a>  
		</li>
		<li>
			Podcast; <span style="font-weight: 1000">Milda Norkute</span>; <span style="font-style: italic">Explainable AI in the Legal Domain</span>; January 27 2022. <a target="_blank" href="https://www.youtube.com/watch?v=1sgUUdNjETU ">link</a>  
		</li>
	</ul>
	<p><span style="font-weight: 1000">2021</span> </p>
	<ul>
		<li>
			Data Innovation Summit;  <span style="font-weight: 1000">Milda Norkute</span> and Nina Hristozova;  <span style="font-style: italic">Explainability for Text Summarization of Legal Documents</span>, Virtual, October 14 2021. <a target="_blank" href="https://www.youtube.com/watch?v=KsfLVeNagGg">promo link</a>  
		</li>

		<li>
			UCAI ’21: Workshop on User-Centered Artificial Intelligence;  <span style="font-weight: 1000">Milda Norkute</span>;  <span style="font-style: italic">The Role of Explanations of AI Systems: Beyond Trust and Helping to Form Mental Models</span>, Virtual, September 5 2021. <a target="_blank" href="https://ucai-sig.org/events/ucai21/program/">link</a>  
		</li>
		<li>
			Summer Institute in Computational Social Science at ETHZ;  <span style="font-weight: 1000">Milda Norkute</span>, Nadja Herger, Aileen Nielsen;  <span style="font-style: italic">Deep Learning-Driven Summarization and the Added Benefit of Explainable AI for Legal Tasks</span>, Virtual, June 23 2021. <a target="_blank" href="https://sicss.io/2021/ethzurich/">link</a>  
		</li>
		<li>
			ACM CHI 2021; <span style="font-weight: 1000">Milda Norkute</span>; <span style="font-style: italic">Towards Explainable AI: Assessing the Usefulness and Impact of Added Explainability Features in Legal Document Summarization</span>; Virtual, May 10 2021. <a target="_blank" href="https://programs.sigchi.org/chi/2021/authors/56298 ">link</a>  
		</li>	
		<li>
			ACM CHI 2021 Workshop on Human-Centered Explainable AI (HCXAI); <span style="font-weight: 1000">Milda Norkute</span>; <span style="font-style: italic">AI Explainability: Why One Explanation Cannot Fit All</span>; Virtual, May 8 2021. <a target="_blank" href="https://hcxai.jimdosite.com/hcxai-21-papers-and-videos/">link</a> 
		</li>
		<li>
			Machine Learning x UX meetup;  <span style="font-weight: 1000">Milda Norkute </span>, <span style="font-style: italic">Designing AI Explainability Features </span>; Virtual, April 28 2021. <a target="_blank" href="https://www.youtube.com/watch?v=CPBmCzP0uww">video</a> 
		</li>
		<li>
			Legal Geek, Thomson Reuters takeover; Nadja Herger, <span style="font-weight: 1000">Milda Norkute</span>, Andrew Fletcher, Eric Wood; <span style="font-style: italic">AI Ethics</span>; Virtual; March 10 2021. <a target="_blank" href="https://www.legalcurrent.com/insights-from-the-thomson-reuters-legal-geek-takeover-ai-ethics"> article</a>
		</li>
	</ul>
</div>
</div>
</div>
</div>
</body>
</html>
